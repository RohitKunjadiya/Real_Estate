{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6625d5bf-49e6-495a-a7be-872289badd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10884ceb-40c5-4c6c-bb40-f5b3b035e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = requests.get('https://housing.com/rent/apartments-for-rent-in-surat-gujarat-M1P20drlq24mltepds2?page=1').text\n",
    "soup = BeautifulSoup(webpage, 'lxml')\n",
    "all_divs = soup.find_all('div', class_=\"t17qvo1u _biqgdtch _1la84ssf _156v13i4 _axkb7n _9s1txw _j61sew T_82a3537f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02dcefcd-5ccb-4a00-9619-c0152994bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlights = []\n",
    "pattern = re.compile(r'(_l8ftgi _vy1osq _c81fwx _gdnqgrho _1q731fwx _4okudlk8 .*? highlights)')\n",
    "\n",
    "for i in all_divs:\n",
    "    \n",
    "    try:\n",
    "        highlights.append(i.find(\"div\", class_=re.compile(r'(_l8ftgi _vy1osq _c81fwx _gdnqgrho _1q731fwx _4okudlk8 .*? highlights)')).text)\n",
    "    except:\n",
    "        highlights.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca620f-13f4-4f6c-9c6a-1ebba2c7cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "\n",
    "for i in range(1, 31):\n",
    "    webpage = requests.get(f'https://housing.com/rent/apartments-for-rent-in-surat-gujarat-M1P20drlq24mltepds2?page={i}').text\n",
    "    soup = BeautifulSoup(webpage, 'lxml')\n",
    "    all_divs = soup.find_all('div', class_=\"t17qvo1u _biqgdtch _1la84ssf _156v13i4 _axkb7n _9s1txw _j61sew T_82a3537f\")\n",
    "\n",
    "    # Lists for collecting data for each property\n",
    "    society_name = []\n",
    "    bhk = []\n",
    "    description = []\n",
    "    highlights = []\n",
    "    furnishing = []\n",
    "    built_up_area = []\n",
    "    locality = []\n",
    "    nearby_place1 = []\n",
    "    distance_away1 = []\n",
    "    nearby_place2 = []\n",
    "    distance_away2 = []\n",
    "\n",
    "    # Loop through each div containing property info\n",
    "    for j in all_divs:\n",
    "        try:\n",
    "            society_name.append(j.find(\"a\", class_=\"value\").text)\n",
    "        except:\n",
    "            society_name.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            bhk.append(j.find(\"div\", class_=\"T_091c165f _sq1l2s _vv1q9c _ks15vq T_3d3547ab _7s5wglyw _5vy24jg8 _blas1v10 new-title\").text)\n",
    "        except:\n",
    "            bhk.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            description.append(j.find(\"span\", class_=\"T_091c165f _sq1l2s _vv1q9c _ks15vq T_3b18a44b _w41hna _7l14la _g3dlk8 _c81fwx\").text)\n",
    "        except:\n",
    "            description.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            highlights.append(j.find(\"div\", class_=re.compile(r'(_l8ftgi _vy1osq _c81fwx _gdnqgrho _1q731fwx _4okudlk8 .*? highlights)')).text)\n",
    "        except:\n",
    "            highlights.append(np.nan)\n",
    "        \n",
    "        x = j.find_all(\"div\", class_=\"T_091c165f _sq1l2s _vv1q9c _ks15vq T_efe231cd _vy1ipv _7ltvct _g3dlk8 _c81fwx _cs1nn1 value\")\n",
    "\n",
    "        # Try to extract each attribute if it exists\n",
    "        try: furnishing.append(x[0].text)\n",
    "        except: furnishing.append(np.nan)\n",
    "        try: built_up_area.append(x[1].text)\n",
    "        except: built_up_area.append(np.nan)\n",
    "        try:locality.append(j.a.get_text())\n",
    "        except:locality.append(np.nan)\n",
    "\n",
    "        y = j.find_all(\"div\", class_=\"T_091c165f _sq1l2s _vv1q9c _ks15vq T_7e22db16 _gz14y2 _j3r5k8 _7l5yda _g3dlk8 _c81fwx\")\n",
    "\n",
    "        try: nearby_place1.append(y[0].text)\n",
    "        except: nearby_place1.append(np.nan)\n",
    "        try: nearby_place2.append(y[1].text)\n",
    "        except: nearby_place2.append(np.nan)\n",
    "\n",
    "        z = j.find_all(\"div\", class_=\"_c81fwx _g3dlk8 _7l11ef _gz1l7b _vy1ris T_b1c2c114\")\n",
    "\n",
    "        try: distance_away1.append(z[0].text)\n",
    "        except: distance_away1.append(np.nan)\n",
    "        try: distance_away2.append(z[1].text)\n",
    "        except: distance_away2.append(np.nan)\n",
    "\n",
    "    # Create a DataFrame for the current page and append it to the list\n",
    "    df = pd.DataFrame({\n",
    "        'SocietyName': society_name,\n",
    "        'BHK': bhk,\n",
    "        'Furnishing': furnishing,\n",
    "        'BuiltUpArea': built_up_area,\n",
    "        'Locality': locality,\n",
    "        'NearbyPlace_1': nearby_place1,\n",
    "        'DistanceAway_1': distance_away1,\n",
    "        'NearbyPlace_2': nearby_place2,\n",
    "        'DistanceAway_2': distance_away2,\n",
    "        'Description': description,\n",
    "        'Highlights': highlights\n",
    "    })\n",
    "    \n",
    "    data_frames.append(df)  # Add the current page DataFrame to the list\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "final_df.to_csv(\"apartment.csv\", index=False)\n",
    "\n",
    "# Display the first few rows of the final DataFrame\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d7553-4e07-49ed-bddd-a5072b57edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab5568-8b38-420f-9f1f-47795d8499f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87ef1f-4628-43f6-a150-7d2eed0aaf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d2472-5716-43ee-9d40-fd659180bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Furnishing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd398d-27d1-4a3f-ac12-9265886f3625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop\n",
    "# 21: shape: 590\n",
    "#     duplicated: 21\n",
    "\n",
    "# 31: shape: 620\n",
    "#     duplicated: 55\n",
    "\n",
    "# 41: shape: 650\n",
    "#     duplicated: 85\n",
    "\n",
    "# 51: shape: 680\n",
    "#     duplicated: 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fd4ce-8c56-44ba-b9c0-ce737eff2ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
